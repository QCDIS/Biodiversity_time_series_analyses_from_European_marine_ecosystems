{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c595e0-33ba-4aae-890f-ad44c397429a",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(\"readxl\")\n",
    "library(dplyr)\n",
    "\n",
    "# Data cleaning----\n",
    "# Load data & metadata\n",
    "md <- read_excel(\"Template_MBO_Example_raw.xlsx\", sheet = \"METADATA\") #Load metadata sheet\n",
    "data <- read_excel(\"Template_MBO_Example_raw.xlsx\", sheet = \"BIRDS\") #Load data sheet (in this example: \"BIRDS\")\n",
    "\n",
    "# Create a table with sites with more that 7 sampling years\n",
    "sites <- data %>% \n",
    "  group_by(siteid) %>%\n",
    "  summarise(nyear = n_distinct(substr(datecollected, 1, 4))) %>%\n",
    "  filter(nyear > 7)\n",
    "\n",
    "md <- merge(md,sites, by = \"siteid\")\n",
    "\n",
    "# Keep sites within the study area [our boundaries are latitude (25:90), longitude (-45:70)]\n",
    "md <- filter(md, decimallatitude >= 25, decimallatitude <= 90, \n",
    "                 decimallongitude >= -45, decimallongitude <= 70)\n",
    "\n",
    "data <- data %>% # Keep data from these sites\n",
    "  filter(siteid %in% md$siteid)\n",
    "\n",
    "# Check that depth is ~constant \n",
    "#(in this case is not necessary, but for other taxonomic groups is possible that the sample were taken at different depths)\n",
    "for (i in names(table(data$siteid))){\n",
    "  x <- filter(data, siteid == i)\n",
    "  print(table(x$maximumdepthinmeters))\n",
    "}\n",
    "\n",
    "# Check sampling dates\n",
    "for (i in names(table(data$siteid))){\n",
    "  x <- filter(data, siteid == i)\n",
    "  print(table(x$datecollected))\n",
    "}\n",
    "\n",
    "# In this case, most of the sampling campaigns were conducted in winter\n",
    "# One was conducted in summer and should be removed since the sampling season is not consistent\n",
    "\n",
    "data$month <- as.numeric(format(data$datecollected, \"%m\")) # Create a column with the sampling month\n",
    "\n",
    "data <- data %>%\n",
    "  filter(!month %in% c(8)) #Remove those samples in non-consistent seasons (summer in this case)\n",
    "\n",
    "# Note that some time series can have more than one sampling campaign per year and even per season (not in this case)\n",
    "# For our analysis, we are only keeping one sampling campaign per year\n",
    "\n",
    "\n",
    "# Update the table with sites with more that 7 sampling years\n",
    "# After removing inconsistent sampling campaigns, some time series may become shorter than 8 years\n",
    "sites <- data %>% \n",
    "  group_by(siteid) %>%\n",
    "  summarise(nyear = n_distinct(substr(datecollected, 1, 4))) %>%\n",
    "  filter(nyear > 7)\n",
    "\n",
    "data <- data %>% # Keep data from these sites\n",
    "  filter(siteid %in% md$siteid)\n",
    "md <- md %>% # Keep metadata from these sites\n",
    "  filter(siteid %in% md$siteid)\n",
    "\n",
    "md_final <- md[,c(1:8)]\n",
    "data_final <- data[,c(1:15)]\n",
    "\n",
    "write.csv(md_final, file = \"metadata_Example.csv\")\n",
    "write.csv(data_final, file = \"data_Example.csv\")\n",
    "\n",
    "# Trend analysis----\n",
    "library(vegan)\n",
    "library(dplyr)\n",
    "library(ggplot2)\n",
    "library(nlme)\n",
    "\n",
    "# Load cleaned data & metadata\n",
    "md <- read.csv(\"metadata_Example.csv\", sep = \",\")\n",
    "data <- read.csv(\"data_Example.csv\", sep = \",\")\n",
    "data$year <- as.numeric(format(as.Date(data$datecollected), \"%Y\"))\n",
    "colnames(data)\n",
    "\n",
    "# Calculate community metrics  \n",
    "data.tax <- data %>%\n",
    "  group_by(siteid, year, datecollected) %>%\n",
    "  summarise(richness = n_distinct(taxaname[parameter_value > 0]), # Richness\n",
    "            parameter_value_tot = sum(parameter_value), # Abundance estimate\n",
    "            parameter = unique(parameter),\n",
    "            parameter_standardunit = unique(parameter_standardunit),\n",
    "            diversity = diversity(parameter_value, index=\"shannon\"), # Diversity\n",
    "            )\n",
    "\n",
    "# Temporal analysis. Example with Richness and these 2 time series\n",
    "results.richness <- data.frame(siteid = character(0), slope = numeric(0), p = numeric(0))\n",
    "\n",
    "for (i in names(table(data.tax$siteid))) {\n",
    "  x <- subset(data.tax, siteid == i)\n",
    "  # We used GLS models taking into account the temporal autocorrelation\n",
    "  gls_model <- gls(log10(richness+1) ~ year, data = x, correlation = corAR1(form = ~ 1 | year))\n",
    "  slope <- coef(gls_model)[2]  \n",
    "  p <- summary(gls_model)$tTable[2, 4]  \n",
    "  \n",
    "  # Save results\n",
    "  results.richness <- rbind(results.richness, data.frame(siteid = i, slope = slope, p = p))\n",
    "}\n",
    "\n",
    "print(results.richness)\n",
    "\n",
    "# In this example the second site showed a significant decrease in Richness over time (p<0.05)\n",
    "\n",
    "final_results <- merge(md,results.richness, by = \"siteid\"); final_results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e93b1c-73ab-44cd-9a54-4674d75a6fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R [conda env:wiresits]",
   "language": "R",
   "name": "conda-env-wiresits-r"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
